{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygsheets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import praw\n",
    "import datetime as dt\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get reddit instance for PRAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client_id = os.getenv(\"client_id\")\n",
    "client_secret = os.getenv(\"client_secret\")\n",
    "username = os.getenv(\"user\")\n",
    "password = os.getenv(\"password\")\n",
    "user_agent = os.getenv(\"user_agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an authorized reddit instance\n",
    "def login(client_id, client_secret, username, password, user_agent):\n",
    "    reddit = praw.Reddit(client_id = client_id,\n",
    "                     client_secret = client_secret,\n",
    "                     username = username,\n",
    "                     password = password,\n",
    "                     user_agent = user_agent)\n",
    "    return reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = login(client_id, client_secret, username, password, user_agent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get google sheets instance for pygsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "secretsPath = r\"client_secret_623798116104-13e1be1fv1ucarscmae78mdvftdbu2tg.apps.googleusercontent.com.json\"\n",
    "gc = pygsheets.authorize(outh_file=secretsPath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open google sheet/worksheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = gc.open(\"pySheets\")\n",
    "wks = sh.worksheet_by_title(\"postInfo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updatePosts(subList=['test'], timeFilter='week', setLimit=100, wksToUse=wks, rInstance=reddit): # dfToUse=df if we decide to put df back in here\n",
    "    \"\"\"\n",
    "    Function to update the google worksheet we are using.  \n",
    "    This function goes through each subreddit in subList individually so as to get top posts for each subreddit rather than their combined subreddit object\n",
    "    \n",
    "    Args:\n",
    "        subList (list): list of all subreddits to iterate over\n",
    "        timeFilter (str): length of time to look through top posts.  Possible options of 'hour', 'day', 'week', 'month'\n",
    "        setLimit (int): number of top posts to look at within the timeframe\n",
    "        dfToUse (dataframe): the dataframe we will put our submission data into for further use\n",
    "        wksToUse (pygsheets.worksheet.Worksheet): the worksheet we'll be updating\n",
    "        rInstance (praw.reddit.Reddit): the reddit instance we'll be using to extract posts\n",
    "    \"\"\"\n",
    "    for subr in subList:\n",
    "        print(f\"Starting {subr}\")\n",
    "        subrInstance = rInstance.subreddit(subr)\n",
    "        firstCellCheck = wksToUse.get_all_values(include_tailing_empty_rows=False, include_tailing_empty=False, returnas='matrix')  \n",
    "        currentIDs = [r[6] for i, r in enumerate(firstCellCheck[1:])]  # Get list of all current post IDs in our sheet\n",
    "        for submission in subrInstance.top(time_filter=timeFilter, limit=setLimit):\n",
    "            if submission.id in currentIDs:  # Don't repeat posts!\n",
    "                continue\n",
    "            else:\n",
    "                try:\n",
    "                    d = {}\n",
    "                    d['timeCreated'] = dt.datetime.fromtimestamp(submission.created_utc)\n",
    "                    d['subreddit'] = submission.subreddit.display_name\n",
    "                    d['title'] = submission.title\n",
    "                    d['score'] = submission.score\n",
    "                    d['author'] = submission.author.name\n",
    "                    d['selftext'] = submission.selftext\n",
    "                    d['id'] = str(submission.id)\n",
    "                    # dfToUse = pd.concat([dfToUse,pd.DataFrame.from_dict(d, orient='index').T], ignore_index=True, axis=0)\n",
    "                    \n",
    "                    cells = wksToUse.get_all_values(include_tailing_empty_rows=False, include_tailing_empty=False, returnas='matrix')  \n",
    "                    lastrow = len(cells)  # Must update every time so as to properly append rows\n",
    "                    \n",
    "                    # make the timeCreated json serializable for appending to worksheet\n",
    "                    dvals = list(d.values())\n",
    "                    dvals[0] = dvals[0].isoformat()\n",
    "                    \n",
    "                    \n",
    "                    wksToUse.insert_rows(lastrow, number=1, values=dvals)\n",
    "                except AttributeError:  # Can occur when an author deletes their account, a post is deleted, etc.\n",
    "                    continue\n",
    "            \n",
    "        print(f\"{subr} complete\")\n",
    "        \n",
    "    print(\"All subreddits complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "testvals = wks.get_all_values(include_tailing_empty_rows=False, include_tailing_empty=False, returnas='matrix')  \n",
    "currentIDs = [r[6] for i, r in enumerate(testvals[1:])]\n",
    "if '123rfgy' in currentIDs:\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting news\n",
      "news complete\n",
      "Starting nottheonion\n",
      "nottheonion complete\n",
      "Starting inthenews\n",
      "inthenews complete\n",
      "Starting offbeat\n",
      "offbeat complete\n",
      "All subreddits complete\n"
     ]
    }
   ],
   "source": [
    "updatePosts(subList=['news', 'nottheonion', 'inthenews', 'offbeat'], timeFilter='month', setLimit=200)  # Lets test with some google-suggested news subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanSheetByTime(clientToUse=gc, sheetToUse=sh, wksToUse=wks):\n",
    "    \"\"\"\n",
    "    Function to clean a given worksheet by the timeCreated column.  This function uses the clientToUse \n",
    "    pygsheets client to look at the wksToUse worksheet within the sheetToUse spreadsheet.\n",
    "    It then removes any rows where the timeCreated column shows a post is from more than a week ago.\n",
    "    \n",
    "    Args:\n",
    "        clientToUse (pygsheets.client.Client): the pygsheets client we'll be using\n",
    "        sheetToUse (pygsheets.spreadsheet.Spreadsheet): the pygsheets spreadsheet we'll be cleaning in\n",
    "        wksToUse (pygsheets.worksheet.Worksheet): the worksheet we'll be cleaning\n",
    "    \"\"\"\n",
    "    cells = wksToUse.get_all_values(include_tailing_empty_rows=False, include_tailing_empty=False, returnas='matrix')  \n",
    "    timeNow = dt.datetime.now()\n",
    "    cutoffTime = timeNow - dt.timedelta(weeks=4)  # Set the cutoff time\n",
    "    # rowsToDelete = [i+2 for i, r in enumerate(cells[1:]) if (dt.datetime.strptime(r[0], \"%Y-%m-%d %H:%M:%S\")  <=  dt.datetime.strptime(\"2023-03-27 0:17:11\", \"%Y-%m-%d %H:%M:%S\"))] # For testing specific time\n",
    "    rowsToDelete = [i+2 for i, r in enumerate(cells[1:]) if (dt.datetime.strptime(r[0], \"%Y-%m-%d %H:%M:%S\")  <=  cutoffTime)]  # i+2 as 1 for removing 1st row of cells and another for sheets counting from 1 instead of 0\n",
    "\n",
    "    # reqs just tells batch_update which rows to delete using the API wrapper\n",
    "    reqs = [\n",
    "    {\n",
    "        \"deleteDimension\": {\n",
    "            \"range\": {\n",
    "                \"sheetId\": wksToUse.id,\n",
    "                \"startIndex\": e-1,\n",
    "                \"endIndex\": e,\n",
    "                \"dimension\": \"ROWS\",\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    for e in rowsToDelete\n",
    "    ]\n",
    "    reqs.reverse()\n",
    "    clientToUse.sheet.batch_update(sheetToUse.id, reqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanSheetByTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeCreated</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>author</th>\n",
       "      <th>selftext</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-27 11:02:12</td>\n",
       "      <td>news</td>\n",
       "      <td>Multiple victims reported in Nashville school ...</td>\n",
       "      <td>62351</td>\n",
       "      <td>cubernetics</td>\n",
       "      <td></td>\n",
       "      <td>123rfgy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-24 8:07:33</td>\n",
       "      <td>news</td>\n",
       "      <td>Top lawyers defy bar to declare they will not ...</td>\n",
       "      <td>56335</td>\n",
       "      <td>je97</td>\n",
       "      <td></td>\n",
       "      <td>120jqqv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-25 10:31:09</td>\n",
       "      <td>news</td>\n",
       "      <td>First female police officer in rural Michigan ...</td>\n",
       "      <td>51934</td>\n",
       "      <td>kaiserintaylor</td>\n",
       "      <td></td>\n",
       "      <td>121pghi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-26 22:05:32</td>\n",
       "      <td>news</td>\n",
       "      <td>Italian museum invites U.S. school after princ...</td>\n",
       "      <td>48707</td>\n",
       "      <td>Pandabum1</td>\n",
       "      <td></td>\n",
       "      <td>1239bjy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-25 4:18:48</td>\n",
       "      <td>news</td>\n",
       "      <td>Kansas City Police targeted minority neighborh...</td>\n",
       "      <td>44377</td>\n",
       "      <td>sue_me_please</td>\n",
       "      <td></td>\n",
       "      <td>121geea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           timeCreated subreddit  \\\n",
       "0  2023-03-27 11:02:12      news   \n",
       "1   2023-03-24 8:07:33      news   \n",
       "2  2023-03-25 10:31:09      news   \n",
       "3  2023-03-26 22:05:32      news   \n",
       "4   2023-03-25 4:18:48      news   \n",
       "\n",
       "                                               title  score          author  \\\n",
       "0  Multiple victims reported in Nashville school ...  62351     cubernetics   \n",
       "1  Top lawyers defy bar to declare they will not ...  56335            je97   \n",
       "2  First female police officer in rural Michigan ...  51934  kaiserintaylor   \n",
       "3  Italian museum invites U.S. school after princ...  48707       Pandabum1   \n",
       "4  Kansas City Police targeted minority neighborh...  44377   sue_me_please   \n",
       "\n",
       "  selftext       id  \n",
       "0           123rfgy  \n",
       "1           120jqqv  \n",
       "2           121pghi  \n",
       "3           1239bjy  \n",
       "4           121geea  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = wks.get_as_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nerWks = sh.worksheet_by_title(\"nerInfo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNER(sourceWks=wks, nerWks=nerWks ):\n",
    "\n",
    "    df = sourceWks.get_as_df()  # Get the postInfo worksheet as a dataframe\n",
    "    \n",
    "    firstCellCheck = nerWks.get_all_values(include_tailing_empty_rows=False, include_tailing_empty=False, returnas='matrix')  \n",
    "    currentIDs = [r[0] for i, r in enumerate(firstCellCheck[1:])]  # Get list of all current post IDs in our sheet\n",
    "    \n",
    "    NER = spacy.load(\"en_core_web_sm\")\n",
    "    print(f\"There are {len(df)} rows in the source worksheet\")\n",
    "    for i, row in df.iterrows():\n",
    "        if i % 50 == 0:\n",
    "            print(f\"{i}th row completed\")\n",
    "        if row['id'] in currentIDs:  # Don't repeat work!\n",
    "            continue\n",
    "        else:\n",
    "            d = {}\n",
    "            d['postID'] = str(row['id'])\n",
    "            nerText = NER(row['title'] + \" \" + row['selftext'])\n",
    "            for word in nerText.ents:\n",
    "                d['nerWord'] = str(word.text)\n",
    "                d['nerLabel'] = str(word.label_)\n",
    "                cells = nerWks.get_all_values(include_tailing_empty_rows=False, include_tailing_empty=False, returnas='matrix')  \n",
    "                lastrow = len(cells)\n",
    "                dvals = list(d.values())\n",
    "                # print(d)\n",
    "                nerWks.insert_rows(lastrow, number=1, values=dvals)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1005 rows in the source worksheet\n",
      "0th row completed\n",
      "50th row completed\n",
      "100th row completed\n",
      "150th row completed\n",
      "200th row completed\n",
      "250th row completed\n",
      "300th row completed\n",
      "350th row completed\n",
      "400th row completed\n",
      "450th row completed\n",
      "500th row completed\n",
      "550th row completed\n",
      "600th row completed\n",
      "650th row completed\n"
     ]
    }
   ],
   "source": [
    "getNER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postID</th>\n",
       "      <th>nerWord</th>\n",
       "      <th>nerLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123rfgy</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121pghi</td>\n",
       "      <td>First</td>\n",
       "      <td>ORDINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121pghi</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11ymeqt</td>\n",
       "      <td>Andrew Tate:</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1239bjy</td>\n",
       "      <td>Italian</td>\n",
       "      <td>NORP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    postID       nerWord nerLabel\n",
       "0  123rfgy     Nashville      GPE\n",
       "1  121pghi         First  ORDINAL\n",
       "2  121pghi      Michigan      GPE\n",
       "3  11ymeqt  Andrew Tate:   PERSON\n",
       "4  1239bjy       Italian     NORP"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = nerWks.get_as_df()\n",
    "df2.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py106",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
