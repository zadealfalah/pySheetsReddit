{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import praw\n",
    "import datetime as dt\n",
    "import mysql.connector\n",
    "from mysql.connector import errorcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "client_id = os.getenv(\"client_id\")\n",
    "client_secret = os.getenv(\"client_secret\")\n",
    "username = os.getenv(\"user\")\n",
    "password = os.getenv(\"password\")\n",
    "user_agent = os.getenv(\"user_agent\")\n",
    "secretpath = os.getenv(\"secret_path\")  # For google client secrets json file\n",
    "sheetName = os.getenv(\"sheet_name\")  # Sheet to use\n",
    "commentWksName = os.getenv(\"comment_workshet_name\")  # Worksheet within the sheet to use to store comments\n",
    "nerWksName = os.getenv(\"ner_worksheet_name\")  # Worksheet within the sheet to use to store NER info\n",
    "\n",
    "subredditsToUse = os.getenv(\"subredditsToUse\")  # space separated list of subreddits to look through\n",
    "subredditsToUse = subredditsToUse.split()  # Turns the os values into a list used later on\n",
    "timeframe = os.getenv(\"timeframe\")  # Timeframe you wish to use e.g. 'weeks', 'days', etc\n",
    "timeInt = os.getenv(\"timeInt\")  # number of timeframes you wish to use e.g. a 2 here with timeframe == 'weeks' uses 2 weeks of data\n",
    "numberOfPosts = os.getenv(\"num_posts\")  # Number of posts you want to look at, at most, for each subreddit\n",
    "\n",
    "mysqluser = os.getenv(\"mysqluser\")\n",
    "mysqlpassword = os.getenv(\"mysqlpassword\")\n",
    "mysqlhost = os.getenv(\"mysqlhost\")\n",
    "mysqldatabase = os.getenv(\"mysqldatabase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login(client_id, client_secret, username, password, user_agent):\n",
    "    reddit = praw.Reddit(client_id = client_id,\n",
    "                     client_secret = client_secret,\n",
    "                     username = username,\n",
    "                     password = password,\n",
    "                     user_agent = user_agent)\n",
    "    return reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['news', 'nottheonion', 'inthenews', 'offbeat']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit = login(client_id, client_secret, username, password, user_agent)\n",
    "subredditsToUse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnx = mysql.connector.connect(user=mysqluser, password=mysqlpassword,\n",
    "#                               host=mysqlhost, database=mysqldatabase)\n",
    "# cursor = cnx.cursor()\n",
    "# add_post = (\"INSERT INTO postinfo \"\n",
    "#             \"(id, author, score, title, subreddit, timecreated) \"\n",
    "#             \"VALUES (%s, %s, %s, %s, %s, %s)\")\n",
    "# add_ner = (\"INSERT INTO nerinfo \"\n",
    "#            \"(nerword, nerlabel, postid) \"\n",
    "#            \"VALUES (%s, %s, %s)\")\n",
    "\n",
    "# data_post = ('2321', 'cs33sf3scs', 6235551, 'Mu4sg4dgd in Nashville school shooting', 'news', '2022-03-27 11:02:12')\n",
    "# cursor.execute(add_post, data_post)\n",
    "# cnx.commit()\n",
    "# cursor.close()\n",
    "# cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updatePosts(subList=subredditsToUse, timeFilter=timeframe, setLimit=numberOfPosts, rInstance=reddit): \n",
    "    \"\"\"\n",
    "    Function to update the google worksheet we are using.  \n",
    "    This function goes through each subreddit in subList individually so as to get top posts for each subreddit rather than their combined subreddit object\n",
    "    \n",
    "    Args:\n",
    "        subList (list): list of all subreddits to iterate over\n",
    "        timeFilter (str): length of time to look through top posts.  Possible options of 'hour', 'day', 'week', 'month'\n",
    "        setLimit (int): number of top posts to look at within the timeframe\n",
    "        dfToUse (dataframe): the dataframe we will put our submission data into for further use\n",
    "        wksToUse (pygsheets.worksheet.Worksheet): the worksheet we'll be updating\n",
    "        rInstance (praw.reddit.Reddit): the reddit instance we'll be using to extract posts\n",
    "    \"\"\"\n",
    "    add_post = (\"INSERT INTO postinfo \"\n",
    "            \"(id, author, score, title, subreddit, timecreated) \"\n",
    "            \"VALUES (%s, %s, %s, %s, %s, %s)\")\n",
    "    \n",
    "    cnx = mysql.connector.connect(user=mysqluser, password=mysqlpassword,\n",
    "                            host=mysqlhost, database=mysqldatabase)\n",
    "    cursor = cnx.cursor()\n",
    "    for subr in subList:\n",
    "        subrInstance = rInstance.subreddit(subr)\n",
    "        for submission in subrInstance.top(time_filter=timeFilter, limit=setLimit):\n",
    "            try: \n",
    "                data_post = (str(submission.id), str(submission.author), int(submission.score), \n",
    "                             str(submission.title), str(submission.subreddit.display_name), \n",
    "                             dt.datetime.fromtimestamp(submission.created_utc))\n",
    "                cursor.execute(add_post, data_post)\n",
    "                cnx.commit()\n",
    "            except:  #Cannot excplitly except an IntegrityError in python\n",
    "                continue\n",
    "    \n",
    "    cursor.close()\n",
    "    cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updatePosts(timeFilter='day', setLimit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 123rfgy\n",
      "ID: 126ng0k\n",
      "ID: 126r8zc\n",
      "ID: 126rvhh\n",
      "ID: 126s4nj\n"
     ]
    }
   ],
   "source": [
    "cnx = mysql.connector.connect(user=mysqluser, password=mysqlpassword,\n",
    "                            host=mysqlhost, database=mysqldatabase)\n",
    "cursor = cnx.cursor()\n",
    "query = (\"SELECT id FROM postinfo LIMIT 5\")\n",
    "cursor.execute(query)\n",
    "bucket = []\n",
    "for nerID in cursor:\n",
    "    print(f\"ID: {nerID[0]}\")\n",
    "    bucket.append(nerID[0])\n",
    "cursor.close()\n",
    "cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['123rfgy', '126ng0k', '126r8zc', '126rvhh', '126s4nj']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if '123rfgy' in bucket:\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            try: \n",
    "                data_post = (str(submission.id), str(submission.author), int(submission.score), \n",
    "                             str(submission.title), str(submission.subreddit.display_name), \n",
    "                             dt.datetime.fromtimestamp(submission.created_utc))\n",
    "                cursor.execute(add_post, data_post)\n",
    "                cnx.commit()\n",
    "            except:  #Cannot excplitly except an IntegrityError in python\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNER():\n",
    "    add_ner = (\"INSERT INTO nerinfo \"\n",
    "           \"(nerword, nerlabel, postid) \"\n",
    "           \"VALUES (%s, %s, %s)\")\n",
    "    \n",
    "    NER = spacy.load(\"en_core_web_sm\")\n",
    "    cnx = mysql.connector.connect(user=mysqluser, password=mysqlpassword,\n",
    "                            host=mysqlhost, database=mysqldatabase)\n",
    "    cursor = cnx.cursor()\n",
    "    query = (\"SELECT id FROM nerinfo\")\n",
    "    cursor.execute(query)\n",
    "    currentIDs = []  # bucket to hold all IDs of posts which have already had NER analysis done before this call of getNER()\n",
    "    cursor.close()\n",
    "    for nerID in cursor:\n",
    "        currentIDs.append(nerID[0])\n",
    "    \n",
    "    cursor = cnx.cursor() #new cursor for selecting \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        \n",
    "        d = {}\n",
    "        d['postID'] = str(row['id'])\n",
    "        nerText = NER(row['title'] + \" \" + row['selftext'])\n",
    "        for word in nerText.ents:\n",
    "            d['nerWord'] = str(word.text)\n",
    "            d['nerLabel'] = str(word.label_)\n",
    "            cells = nerWks.get_all_values(include_tailing_empty_rows=False, include_tailing_empty=False, returnas='matrix')  \n",
    "            lastrow = len(cells)\n",
    "            dvals = list(d.values())\n",
    "            # print(d)\n",
    "            nerWks.insert_rows(lastrow, number=1, values=dvals)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py1010-red",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab81c42532e0a732ba125b77f7aff1a73b0e9650de495f29e44898b95b522568"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
